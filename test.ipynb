{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -ttpx (/workspaces/ccf-app-template/.venv/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting torch\n",
      "  Using cached torch-2.1.2-cp38-cp38-manylinux1_x86_64.whl.metadata (25 kB)\n",
      "Collecting torchvision\n",
      "  Using cached torchvision-0.16.2-cp38-cp38-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Using cached filelock-3.13.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: typing-extensions in ./.venv/lib/python3.8/site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: sympy in ./.venv/lib/python3.8/site-packages (from torch) (1.12)\n",
      "Collecting networkx (from torch)\n",
      "  Using cached networkx-3.1-py3-none-any.whl (2.1 MB)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.8/site-packages (from torch) (3.1.3)\n",
      "Collecting fsspec (from torch)\n",
      "  Using cached fsspec-2023.12.2-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./.venv/lib/python3.8/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./.venv/lib/python3.8/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./.venv/lib/python3.8/site-packages (from torch) (12.1.105)\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
      "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
      "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./.venv/lib/python3.8/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./.venv/lib/python3.8/site-packages (from torch) (10.3.2.106)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
      "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
      "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in ./.venv/lib/python3.8/site-packages (from torch) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./.venv/lib/python3.8/site-packages (from torch) (12.1.105)\n",
      "Collecting triton==2.1.0 (from torch)\n",
      "  Using cached triton-2.1.0-0-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./.venv/lib/python3.8/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.3.101)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.8/site-packages (from torchvision) (1.24.4)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.8/site-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./.venv/lib/python3.8/site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.8/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.8/site-packages (from requests->torchvision) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.8/site-packages (from requests->torchvision) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.8/site-packages (from requests->torchvision) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.8/site-packages (from requests->torchvision) (2023.11.17)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./.venv/lib/python3.8/site-packages (from sympy->torch) (1.3.0)\n",
      "Using cached torch-2.1.2-cp38-cp38-manylinux1_x86_64.whl (670.2 MB)\n",
      "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "Using cached triton-2.1.0-0-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n",
      "Using cached torchvision-0.16.2-cp38-cp38-manylinux1_x86_64.whl (6.8 MB)\n",
      "Using cached filelock-3.13.1-py3-none-any.whl (11 kB)\n",
      "Using cached fsspec-2023.12.2-py3-none-any.whl (168 kB)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ttpx (/workspaces/ccf-app-template/.venv/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: nvidia-cusparse-cu12, nvidia-cublas-cu12, networkx, fsspec, filelock, triton, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchvision\n",
      "Successfully installed filelock-3.13.1 fsspec-2023.12.2 networkx-3.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cudnn-cu12-8.9.2.26 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 torch-2.1.2 torchvision-0.16.2 triton-2.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response from server: {\"message\":\"Model uploaded successfully\",\"model_id\":3,\"model_name\":\"CustomModel\"}\n",
      "Initial custom model uploaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import json\n",
    "import base64\n",
    "\n",
    "# Replace the server URL with your server address\n",
    "server = \"https://127.0.0.1:8000\"\n",
    "\n",
    "def create_custom_model():\n",
    "    # Define your custom CNN model here\n",
    "    # Example: a simple CNN with two convolutional layers and one dense layer\n",
    "    model_definition = {\n",
    "        \"layers\": [\n",
    "            {\"type\": \"conv2d\", \"filters\": 64, \"kernel_size\": 3, \"activation\": \"relu\", \"input_shape\": [28, 28, 1]},\n",
    "            {\"type\": \"maxpooling2d\", \"pool_size\": [2, 2]},\n",
    "            {\"type\": \"conv2d\", \"filters\": 32, \"kernel_size\": 3, \"activation\": \"relu\"},\n",
    "            {\"type\": \"maxpooling2d\", \"pool_size\": [2, 2]},\n",
    "            {\"type\": \"flatten\"},\n",
    "            {\"type\": \"dense\", \"units\": 10, \"activation\": \"softmax\"}\n",
    "        ]\n",
    "    }\n",
    "    return model_definition\n",
    "\n",
    "def serialize_custom_model(model_definition):\n",
    "    # Serialize the model definition to JSON\n",
    "    return json.dumps(model_definition)\n",
    "\n",
    "def encode_to_base64(data):\n",
    "    # Encode data to Base64\n",
    "    return base64.b64encode(data.encode()).decode()\n",
    "\n",
    "def upload_initial_custom_model(json_payload, user_cert, user_key):\n",
    "    # Upload the initial custom model to the server\n",
    "    payload = {\n",
    "       \"global_model\":{\n",
    "            \"model_name\": \"CustomModel\",\n",
    "        \"model_data\": encode_to_base64(json_payload),\n",
    "       }\n",
    "    }\n",
    "\n",
    "    response = subprocess.run([\n",
    "        \"curl\",\n",
    "        \"-X\", \"POST\",\n",
    "        f\"{server}/app/model\",\n",
    "        \"--cacert\", \"./workspace/sandbox_common/service_cert.pem\",\n",
    "        \"--cert\", user_cert,\n",
    "        \"--key\", user_key,\n",
    "        \"-H\", \"Content-Type: application/json\",\n",
    "        \"--data-raw\", json.dumps(payload)\n",
    "    ], capture_output=True, text=True)\n",
    "\n",
    "    print(\"Response from server:\", response.stdout)\n",
    "\n",
    "    if response.returncode == 0:\n",
    "        print(\"Initial custom model uploaded successfully.\")\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"Failed to upload initial custom model. Error: {response.stderr}\")\n",
    "        return False\n",
    "\n",
    "# Initialize and upload initial custom model with JSON data as payload\n",
    "json_payload = serialize_custom_model(create_custom_model())\n",
    "if not upload_initial_custom_model(json_payload, \"./workspace/sandbox_common/user0_cert.pem\", \"./workspace/sandbox_common/user0_privk.pem\"):\n",
    "    raise Exception(\"Failed to upload the initial custom model. Stopping the process.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response from server: {\"error\":{\"code\":\"ResourceNotFound\",\"message\":\"Cannot find model for id \\\"3\\\".\"}}\n",
      "Model downloaded successfully.\n",
      "{\"error\":{\"code\":\"ResourceNotFound\",\"message\":\"Cannot find model for id \\\"3\\\".\"}}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'model_details'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[77], line 39\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Replace MODEL_ID with the actual model ID you want to download\u001b[39;00m\n\u001b[1;32m     38\u001b[0m MODEL_ID \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m  \u001b[38;5;66;03m# Replace with the actual model ID\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m downloaded_model \u001b[38;5;241m=\u001b[39m \u001b[43mdownload_custom_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMODEL_ID\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./workspace/sandbox_common/user0_cert.pem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./workspace/sandbox_common/user0_privk.pem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m downloaded_model:\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;66;03m# Now 'downloaded_model' contains the downloaded model data, you can use it as needed\u001b[39;00m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloaded model data:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[77], line 31\u001b[0m, in \u001b[0;36mdownload_custom_model\u001b[0;34m(model_id, user_cert, user_key)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;66;03m# Decode and return the model data\u001b[39;00m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28mprint\u001b[39m(response\u001b[38;5;241m.\u001b[39mstdout)\n\u001b[0;32m---> 31\u001b[0m     model_data \u001b[38;5;241m=\u001b[39m base64\u001b[38;5;241m.\u001b[39mb64decode(\u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstdout\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel_details\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m)\u001b[38;5;241m.\u001b[39mdecode()\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_data\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'model_details'"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import json\n",
    "import base64\n",
    "\n",
    "# Replace the server URL with your server address\n",
    "server = \"https://127.0.0.1:8000\"\n",
    "\n",
    "def download_custom_model(model_id, user_cert, user_key):\n",
    "    # Specify the model ID to download\n",
    "    download_payload = {\n",
    "        \"model_id\": model_id\n",
    "    }\n",
    "\n",
    "    response = subprocess.run([\n",
    "        \"curl\",\n",
    "        \"-X\", \"GET\",\n",
    "        f\"{server}/app/model?model_id={model_id}\",\n",
    "        \"--cacert\", \"./workspace/sandbox_common/service_cert.pem\",\n",
    "        \"--cert\", user_cert,\n",
    "        \"--key\", user_key,\n",
    "        \"-H\", \"Content-Type: application/json\",\n",
    " \n",
    "    ], capture_output=True, text=True)\n",
    "\n",
    "    print(\"Response from server:\", response.stdout)\n",
    "\n",
    "    if response.returncode == 0:\n",
    "        print(\"Model downloaded successfully.\")\n",
    "        # Decode and return the model data\n",
    "        print(response.stdout)\n",
    "        model_data = base64.b64decode(json.loads(response.stdout)[\"model_details\"]).decode()\n",
    "        return model_data\n",
    "    else:\n",
    "        print(f\"Failed to download model. Error: {response.stderr}\")\n",
    "        return None\n",
    "\n",
    "# Replace MODEL_ID with the actual model ID you want to download\n",
    "MODEL_ID = 3  # Replace with the actual model ID\n",
    "downloaded_model = download_custom_model(MODEL_ID, \"./workspace/sandbox_common/user0_cert.pem\", \"./workspace/sandbox_common/user0_privk.pem\")\n",
    "\n",
    "if downloaded_model:\n",
    "    # Now 'downloaded_model' contains the downloaded model data, you can use it as needed\n",
    "    print(\"Downloaded model data:\")\n",
    "    print(downloaded_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1 to connect to the server...\n",
      "connect error ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Attempt 1 failed. Retrying in 2 seconds.\n",
      "Attempt 2 to connect to the server...\n",
      "connect error ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Attempt 2 failed. Retrying in 2 seconds.\n",
      "Attempt 3 to connect to the server...\n",
      "connect error ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Attempt 3 failed. Retrying in 2 seconds.\n",
      "Maximum number of retries reached. Could not establish a connection.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from requests.exceptions import ConnectionError\n",
    "import time\n",
    "\n",
    "max_retries = 3\n",
    "retry_delay = 2  # seconds\n",
    "\n",
    "for attempt in range(1, max_retries + 1):\n",
    "    try:\n",
    "        headers = {\n",
    "            \"Content-Type\": \"application/json\",\n",
    "        }\n",
    "        print(f\"Attempt {attempt} to connect to the server...\")\n",
    "        response = requests.get(f\"{server}/app/model?model_id={MODEL_ID}\", headers=headers, verify=\"./workspace/sandbox_common/service_cert.pem\", cert=(\"./workspace/sandbox_common/user0_cert.pem\", \"./workspace/sandbox_common/user0_privk.pem\"))\n",
    "        print(\"Response from server:\", response.text)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Process the response here\n",
    "        break  # Success, exit the loop\n",
    "    except ConnectionError as e:\n",
    "        print(\"connect error\",e)\n",
    "        print(f\"Attempt {attempt} failed. Retrying in {retry_delay} seconds.\")\n",
    "        time.sleep(retry_delay)\n",
    "else:\n",
    "    # All attempts failed\n",
    "    print(\"Maximum number of retries reached. Could not establish a connection.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
