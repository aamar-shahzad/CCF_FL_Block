{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status Code: 200\n",
      "\n",
      "Response Headers:\n",
      "content-length: 176\n",
      "content-type: application/json\n",
      "\n",
      "Response Body:\n",
      "{\n",
      "    \"metrics\": [\n",
      "        {\n",
      "            \"calls\": 1,\n",
      "            \"errors\": 0,\n",
      "            \"failures\": 0,\n",
      "            \"method\": \"GET\",\n",
      "            \"path\": \"api/metrics\",\n",
      "            \"retries\": 0\n",
      "        },\n",
      "        {\n",
      "            \"calls\": 2,\n",
      "            \"errors\": 0,\n",
      "            \"failures\": 0,\n",
      "            \"method\": \"GET\",\n",
      "            \"path\": \"commit\",\n",
      "            \"retries\": 0\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "import base64\n",
    "import hashlib\n",
    "from urllib.parse import urlparse\n",
    "import subprocess\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "import glob\n",
    "\n",
    "\n",
    "RSA_SIZE = 2048\n",
    "\n",
    "\n",
    "DEFAULT_CURVE = \"secp384r1\"\n",
    "FAST_CURVE = \"secp256r1\"\n",
    "SUPPORTED_CURVES = [DEFAULT_CURVE, FAST_CURVE]\n",
    "\n",
    "DIGEST_SHA384 = \"sha384\"\n",
    "DIGEST_SHA256 = \"sha256\"\n",
    "\n",
    "RSA_SIZE = 2048\n",
    "# CCF network node\n",
    "server=\"https://127.0.0.1:8000\"\n",
    "\n",
    "num_users = 4\n",
    "# Getting Network metrices\n",
    "url = server + \"/app/api/metrics\"\n",
    "\n",
    "try:\n",
    "    response = requests.get(url, verify='./workspace/sandbox_common/service_cert.pem')\n",
    "\n",
    "    print(\"Status Code:\", response.status_code)\n",
    "    print(\"\\nResponse Headers:\")\n",
    "    for header, value in response.headers.items():\n",
    "        print(f\"{header}: {value}\")\n",
    "\n",
    "    print(\"\\nResponse Body:\")\n",
    "    try:\n",
    "        # Attempt to parse JSON and print it in an indented format\n",
    "        response_json = response.json()\n",
    "        print(json.dumps(response_json, indent=4))\n",
    "    except ValueError:\n",
    "        # If response is not JSON, print as plain text\n",
    "        print(response.text)\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(\"Error making request:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in ./.venv/lib/python3.8/site-packages (3.7.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.8/site-packages (from matplotlib) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.8/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.8/site-packages (from matplotlib) (4.47.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in ./.venv/lib/python3.8/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy<2,>=1.20 in ./.venv/lib/python3.8/site-packages (from matplotlib) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.8/site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in ./.venv/lib/python3.8/site-packages (from matplotlib) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.8/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.8/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in ./.venv/lib/python3.8/site-packages (from matplotlib) (6.1.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in ./.venv/lib/python3.8/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.17.0)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: tensorflow in ./.venv/lib/python3.8/site-packages (2.13.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in ./.venv/lib/python3.8/site-packages (from tensorflow) (2.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in ./.venv/lib/python3.8/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in ./.venv/lib/python3.8/site-packages (from tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in ./.venv/lib/python3.8/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in ./.venv/lib/python3.8/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./.venv/lib/python3.8/site-packages (from tensorflow) (1.60.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in ./.venv/lib/python3.8/site-packages (from tensorflow) (3.10.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in ./.venv/lib/python3.8/site-packages (from tensorflow) (2.13.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in ./.venv/lib/python3.8/site-packages (from tensorflow) (16.0.6)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in ./.venv/lib/python3.8/site-packages (from tensorflow) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in ./.venv/lib/python3.8/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.8/site-packages (from tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in ./.venv/lib/python3.8/site-packages (from tensorflow) (3.20.3)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.8/site-packages (from tensorflow) (44.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in ./.venv/lib/python3.8/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in ./.venv/lib/python3.8/site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in ./.venv/lib/python3.8/site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./.venv/lib/python3.8/site-packages (from tensorflow) (2.4.0)\n",
      "Collecting typing-extensions<4.6.0,>=3.6.6 (from tensorflow)\n",
      "  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in ./.venv/lib/python3.8/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in ./.venv/lib/python3.8/site-packages (from tensorflow) (0.34.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./.venv/lib/python3.8/site-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in ./.venv/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.26.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in ./.venv/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./.venv/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.5.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./.venv/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./.venv/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in ./.venv/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in ./.venv/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./.venv/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./.venv/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in ./.venv/lib/python3.8/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in ./.venv/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow) (7.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2023.11.17)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in ./.venv/lib/python3.8/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: zipp>=0.5 in ./.venv/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow) (3.17.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in ./.venv/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.5.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in ./.venv/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (3.2.2)\n",
      "Installing collected packages: typing-extensions\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.9.0\n",
      "    Uninstalling typing_extensions-4.9.0:\n",
      "      Successfully uninstalled typing_extensions-4.9.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "azure-core 1.29.6 requires typing-extensions>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed typing-extensions-4.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install matplotlib\n",
    "%pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "import base64\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import load_model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPooling2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "server = \"https://127.0.0.1:8000\"  # Replace with your server URL\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def download_global_model_weights(user_cert, user_key, model_id):\n",
    "    print(\"Downloading global model weights...\")\n",
    "    response = requests.get(\n",
    "        url=f\"{server}/app/global_model_weights?model_id={model_id}\",\n",
    "        verify=\"./workspace/sandbox_common/service_cert.pem\",\n",
    "        cert=(user_cert, user_key)\n",
    "    )\n",
    "    print(\"global model weights\",response.text)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        model_weights_data = response.json().get(\"weights_json\", {})\n",
    "        model_weights_base64 = model_weights_data.get(\"model_weights_base64\")\n",
    "\n",
    "        if model_weights_base64:\n",
    "            return json.loads(base64.b64decode(model_weights_base64).decode('utf-8'))\n",
    "        else:\n",
    "            print(\"Global model weights data not found in response.\")\n",
    "    else:\n",
    "        print(f\"Failed to download global model weights. Status code: {response.status_code}\")\n",
    "\n",
    "    return None\n",
    "\n",
    "def create_model():\n",
    "    print(\"Initializing the global model...\")\n",
    "    model = Sequential([\n",
    "        Conv2D(64, kernel_size=3, activation='relu', input_shape=(28, 28, 1)),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Conv2D(32, kernel_size=3, activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(10, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def aggregate_weights(model_id, user_cert, user_key):\n",
    "    print(\"Aggregating weights for model:\", model_id)\n",
    "  \n",
    "    response = requests.put(\n",
    "        url=f\"{server}/app/aggregate_weights?model_id={model_id}\",\n",
    "        verify=\"./workspace/sandbox_common/service_cert.pem\",\n",
    "        cert=(user_cert, user_key)\n",
    "    )\n",
    "    print(response.text)\n",
    "    if response.status_code == 200:\n",
    "        print(\"Aggregation successful for model:\", model_id)\n",
    "    else:\n",
    "        raise Exception(f\"Failed to aggregate weights. Status code: {response.status_code}\")\n",
    "def train_model(model, X_train, y_train, X_test, y_test, user_id, round_no, epochs=2):\n",
    "    print(f\"Training model for User {user_id}, Round {round_no}...\")\n",
    "    history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs)\n",
    "    return history.history['loss']\n",
    "\n",
    "def serialize_model(model):\n",
    "    print(\"Serializing the model...\")\n",
    "    model.save('temp_model.h5')\n",
    "    with open('temp_model.h5', 'rb') as file:\n",
    "        return base64.b64encode(file.read()).decode('utf-8')\n",
    "    \n",
    "\n",
    "def upload_initial_model(model_base64, user_cert, user_key):\n",
    "    print(\"Uploading initial global model...\")\n",
    "    payload = {\n",
    "      \"global_model\": {\n",
    "        \"model_name\": \"CNNModel\",\n",
    "        \"model_data\": model_base64\n",
    "      }\n",
    "    }\n",
    "    response = requests.post(\n",
    "        url=f\"{server}/app/model\",\n",
    "        verify=\"./workspace/sandbox_common/service_cert.pem\",\n",
    "        cert=(user_cert, user_key),\n",
    "        json=payload\n",
    "    )\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        model_data = response.json()\n",
    "        model_id = model_data.get(\"model_id\")\n",
    "        model_name = model_data.get(\"model_name\")\n",
    "        print(f\"Initial global model '{model_name}' (ID: {model_id}) uploaded successfully.\")\n",
    "        return model_id\n",
    "    else:\n",
    "        print(f\"Failed to upload initial model. Status code: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "# def serialize_weights(model):\n",
    "#     \"\"\" Serialize only the weights of the model \"\"\"\n",
    "#     print(\"Serializing model weights...\")\n",
    "#     weights = model.get_weights()  # Get the model weights as a list of numpy arrays\n",
    "#     weights_base64 = base64.b64encode(json.dumps([w.tolist() for w in weights]).encode()).decode()\n",
    "#     return weights_base64\n",
    "def serialize_weights(model):\n",
    "    \"\"\" Serialize only the weights of the model \"\"\"\n",
    "    print(\"Serializing model weights...\")\n",
    "    weights = model.get_weights()  # Get the model weights as a list of numpy arrays\n",
    "    return [w.tolist() for w in weights]\n",
    "\n",
    "\n",
    "def upload_model_weights(model_weights_base64, user_cert, user_key, round_no, model_id=None):\n",
    "    \"\"\" Upload only the model weights \"\"\"\n",
    "    print(f\"Uploading model weights for Round {round_no}...\")\n",
    "    payload = {\n",
    "        \"model_id\": model_id,\n",
    "        \"weights_json\": model_weights_base64,\n",
    "        \"round_no\": round_no\n",
    "    }\n",
    "    response = requests.post(\n",
    "        url=f\"{server}/app/weights\",\n",
    "        verify=\"./workspace/sandbox_common/service_cert.pem\",\n",
    "        cert=(user_cert, user_key),\n",
    "        json=payload\n",
    "    )\n",
    "    print(response.text)\n",
    "    if response:\n",
    "        print(f\"Model weights uploaded successfully for Round {round_no}.\")\n",
    "    else:\n",
    "        raise Exception(f\"Failed to upload model weights. Status code: {response.status_code}\")\n",
    "\n",
    "def download_model(user_cert, user_key, user_id, round_no, max_retries=5, model_id=None):\n",
    "    attempts = 0\n",
    "    while attempts < max_retries:\n",
    "        print(f\"Attempting to download model for User {user_id}, Round {round_no}, Attempt {attempts + 1}...\")\n",
    "        response = requests.get(\n",
    "            url=f\"{server}/app/model?model_id={model_id}\",\n",
    "            verify=\"./workspace/sandbox_common/service_cert.pem\",\n",
    "            cert=(user_cert, user_key)\n",
    "        )\n",
    "  \n",
    "\n",
    "        if response.status_code == 200:\n",
    "            model_data = response.json().get(\"model_details\", {})\n",
    "            model_base64 = model_data\n",
    "            \n",
    "            if model_base64:\n",
    "                with open('temp_model.h5', 'wb') as file:\n",
    "                    file.write(base64.b64decode(model_base64))\n",
    "                return load_model('temp_model.h5')\n",
    "            else:\n",
    "                print(\"Model data not found in response, retrying...\")\n",
    "        else:\n",
    "            print(f\"Failed to download model. Status code: {response.status_code}, retrying...\")\n",
    "        \n",
    "        time.sleep(2)  # Delay before retrying\n",
    "        attempts += 1\n",
    "    \n",
    "    raise Exception(\"Failed to download model after maximum retries.\")\n",
    "\n",
    "def plot_loss(user_losses):\n",
    "    for user_id, losses in user_losses.items():\n",
    "        plt.plot(losses, label=f'User {user_id}')\n",
    "    plt.title('Model Loss per Training Round')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Round')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Load and preprocess MNIST dataset\n",
    "print(\"Loading and preprocessing MNIST dataset...\")\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "# Split the dataset for two users\n",
    "print(\"Splitting dataset for two users...\")\n",
    "split_index = int(len(X_train) / 2)\n",
    "X_train_user0, X_train_user1 = np.split(X_train, [split_index])\n",
    "y_train_user0, y_train_user1 = np.split(y_train, [split_index])\n",
    "\n",
    "# Initialize and train the global model (User 0)\n",
    "global_model = create_model()\n",
    "train_model(global_model, X_train_user0, y_train_user0, X_test, y_test, user_id=0, round_no=0)\n",
    "\n",
    "# Serialize and upload initial global model\n",
    "model_base64 = serialize_model(global_model)\n",
    "\n",
    "initial_model_id = upload_initial_model(model_base64, \"./workspace/sandbox_common/user0_cert.pem\", \"./workspace/sandbox_common/user0_privk.pem\")\n",
    "\n",
    "if initial_model_id is None:\n",
    "    raise Exception(\"Failed to upload the initial global model. Stopping the process.\")\n",
    "\n",
    "# Wait for some time after initial upload\n",
    "time.sleep(1)  # Wait for 10 seconds\n",
    "\n",
    "# Federated Learning Process\n",
    "# Federated Learning Process\n",
    "num_rounds = 4  # Number of training rounds\n",
    "user_losses = {0: [], 1: []}  # To track losses for each user\n",
    "\n",
    "# Download the latest global model once for each client\n",
    "global_model = download_model(\n",
    "    \"./workspace/sandbox_common/user0_cert.pem\",\n",
    "    \"./workspace/sandbox_common/user0_privk.pem\",\n",
    "    user_id=0, round_no=0, model_id=initial_model_id\n",
    ")\n",
    "\n",
    "# Initialize the local models for both users\n",
    "local_model_user0 = global_model\n",
    "local_model_user1 = global_model\n",
    "\n",
    "for round_no in range(1, num_rounds + 1):\n",
    "    for user_id in range(2):  # Two users: 0 and 1\n",
    "        # Train the local model on the user's data\n",
    "        X_train_user = X_train_user0 if user_id == 0 else X_train_user1\n",
    "        y_train_user = y_train_user0 if user_id == 0 else y_train_user1\n",
    "        loss = train_model(local_model_user0 if user_id == 0 else local_model_user1,\n",
    "                           X_train_user, y_train_user, X_test, y_test, user_id, round_no)\n",
    "        user_losses[user_id].extend(loss)\n",
    "\n",
    "        # Serialize and upload the updated model weights for the current round\n",
    "        model_weights_base64 = serialize_weights(local_model_user0 if user_id == 0 else local_model_user1)\n",
    "        # Upload model weights only if they are not empty\n",
    "        if model_weights_base64:\n",
    "            upload_model_weights(model_weights_base64, f\"./workspace/sandbox_common/user{user_id}_cert.pem\",\n",
    "                                 f\"./workspace/sandbox_common/user{user_id}_privk.pem\", round_no, model_id=initial_model_id)\n",
    "        else:\n",
    "            print(\"Model weights are empty, skipping upload...\")\n",
    "\n",
    "    # Aggregate weights after each user's training round\n",
    "    aggregate_weights(initial_model_id, \"./workspace/sandbox_common/member0_cert.pem\",\n",
    "                      \"./workspace/sandbox_common/member0_privk.pem\")\n",
    "\n",
    "    # Download global model weights after aggregation and update local models\n",
    "    global_model_weights = download_global_model_weights(\n",
    "        \"./workspace/sandbox_common/user0_cert.pem\", \"./workspace/sandbox_common/user0_privk.pem\",\n",
    "        model_id=initial_model_id\n",
    "    )\n",
    "\n",
    "    if global_model_weights:\n",
    "        # Update local models with global weights\n",
    "        local_model_user0.set_weights([np.array(w) for w in global_model_weights])\n",
    "        local_model_user1.set_weights([np.array(w) for w in global_model_weights])\n",
    "        print(\"Global model weights updated for both clients.\")\n",
    "\n",
    "print(\"Federated Learning Process Completed.\")\n",
    "\n",
    "# Plot loss graphs for each user\n",
    "plot_loss(user_losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing MNIST dataset...\n",
      "Splitting dataset for two users...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "import base64\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import load_model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPooling2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "server = \"https://127.0.0.1:8000\"  # Replace with your server URL\n",
    "\n",
    "\n",
    "def download_global_model_weights(user_cert, user_key, model_id):\n",
    "    print(\"Downloading global model weights...\")\n",
    "    response = requests.get(\n",
    "        url=f\"{server}/app/global_model_weights?model_id={model_id}\",\n",
    "        verify=\"./workspace/sandbox_common/service_cert.pem\",\n",
    "        cert=(user_cert, user_key)\n",
    "    )\n",
    "    print(\"global model weights\", response.text)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        model_weights_data = response.json().get(\"weights_json\", {})\n",
    "        model_weights_base64 = model_weights_data.get(\"model_weights_base64\")\n",
    "\n",
    "        if model_weights_base64:\n",
    "            return json.loads(base64.b64decode(model_weights_base64).decode('utf-8'))\n",
    "        else:\n",
    "            print(\"Global model weights data not found in response.\")\n",
    "    else:\n",
    "        print(f\"Failed to download global model weights. Status code: {response.status_code}\")\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def create_model():\n",
    "    print(\"Initializing the global model...\")\n",
    "    model = Sequential([\n",
    "        Conv2D(64, kernel_size=3, activation='relu', input_shape=(28, 28, 1)),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Conv2D(32, kernel_size=3, activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(10, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def aggregate_weights(model_id, user_cert, user_key):\n",
    "    print(\"Aggregating weights for model:\", model_id)\n",
    "\n",
    "    response = requests.put(\n",
    "        url=f\"{server}/app/aggregate_weights?model_id={model_id}\",\n",
    "        verify=\"./workspace/sandbox_common/service_cert.pem\",\n",
    "        cert=(user_cert, user_key)\n",
    "    )\n",
    "    print(response.text)\n",
    "    if response.status_code == 200:\n",
    "        print(\"Aggregation successful for model:\", model_id)\n",
    "    else:\n",
    "        raise Exception(f\"Failed to aggregate weights. Status code: {response.status_code}\")\n",
    "\n",
    "\n",
    "def train_model(model, X_train, y_train, X_test, y_test, user_id, round_no, epochs=2):\n",
    "    print(f\"Training model for User {user_id}, Round {round_no}...\")\n",
    "    history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs)\n",
    "    return history.history['loss']\n",
    "\n",
    "\n",
    "def serialize_model(model):\n",
    "    print(\"Serializing the model...\")\n",
    "    model.save('temp_model.h5')\n",
    "    with open('temp_model.h5', 'rb') as file:\n",
    "        return base64.b64encode(file.read()).decode('utf-8')\n",
    "\n",
    "\n",
    "def upload_initial_model(model_base64, user_cert, user_key):\n",
    "    print(\"Uploading initial global model...\")\n",
    "    payload = {\n",
    "        \"global_model\": {\n",
    "            \"model_name\": \"CNNModel\",\n",
    "            \"model_data\": model_base64\n",
    "        }\n",
    "    }\n",
    "    response = requests.post(\n",
    "        url=f\"{server}/app/model\",\n",
    "        verify=\"./workspace/sandbox_common/service_cert.pem\",\n",
    "        cert=(user_cert, user_key),\n",
    "        json=payload\n",
    "    )\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        model_data = response.json()\n",
    "        model_id = model_data.get(\"model_id\")\n",
    "        model_name = model_data.get(\"model_name\")\n",
    "        print(f\"Initial global model '{model_name}' (ID: {model_id}) uploaded successfully.\")\n",
    "        return model_id\n",
    "    else:\n",
    "        print(f\"Failed to upload initial model. Status code: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def upload_model_weights(model_weights, user_cert, user_key, round_no, model_id=None):\n",
    "    \"\"\" Upload model weights without serialization \"\"\"\n",
    "    print(f\"Uploading model weights for Round {round_no}...\")\n",
    "\n",
    "    \n",
    "    # Convert numpy arrays to lists\n",
    "    model_weights_serializable = [w.tolist() for w in model_weights]\n",
    "\n",
    "    \n",
    "\n",
    "    payload = {\n",
    "        \"model_id\": model_id,\n",
    "        \"weights_json\": model_weights_serializable,\n",
    "        \"round_no\": round_no\n",
    "    }\n",
    "    response = requests.post(\n",
    "        url=f\"{server}/app/weights\",\n",
    "        verify=\"./workspace/sandbox_common/service_cert.pem\",\n",
    "        cert=(user_cert, user_key),\n",
    "        json=payload\n",
    "    )\n",
    "    print(response.text)\n",
    "    if response:\n",
    "        print(f\"Model weights uploaded successfully for Round {round_no}.\")\n",
    "    else:\n",
    "        raise Exception(f\"Failed to upload model weights. Status code: {response.status_code}\")\n",
    "\n",
    "\n",
    "def download_model(user_cert, user_key, user_id, round_no, max_retries=5, model_id=None):\n",
    "    attempts = 0\n",
    "    while attempts < max_retries:\n",
    "        print(f\"Attempting to download model for User {user_id}, Round {round_no}, Attempt {attempts + 1}...\")\n",
    "        response = requests.get(\n",
    "            url=f\"{server}/app/model?model_id={model_id}\",\n",
    "            verify=\"./workspace/sandbox_common/service_cert.pem\",\n",
    "            cert=(user_cert, user_key)\n",
    "        )\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            model_data = response.json().get(\"model_details\", {})\n",
    "            model_base64 = model_data\n",
    "\n",
    "            if model_base64:\n",
    "                with open('temp_model.h5', 'wb') as file:\n",
    "                    file.write(base64.b64decode(model_base64))\n",
    "                return load_model('temp_model.h5')\n",
    "            else:\n",
    "                print(\"Model data not found in response, retrying...\")\n",
    "        else:\n",
    "            print(f\"Failed to download model. Status code: {response.status_code}, retrying...\")\n",
    "\n",
    "        time.sleep(2)  # Delay before retrying\n",
    "        attempts += 1\n",
    "\n",
    "    raise Exception(\"Failed to download model after maximum retries.\")\n",
    "\n",
    "\n",
    "def plot_loss(user_losses):\n",
    "    for user_id, losses in user_losses.items():\n",
    "        plt.plot(losses, label=f'User {user_id}')\n",
    "    plt.title('Model Loss per Training Round')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Round')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Load and preprocess MNIST dataset\n",
    "print(\"Loading and preprocessing MNIST dataset...\")\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "# Split the dataset for two users\n",
    "print(\"Splitting dataset for two users...\")\n",
    "split_index = int(len(X_train) / 2)\n",
    "X_train_user0, X_train_user1 = np.split(X_train, [split_index])\n",
    "y_train_user0, y_train_user1 = np.split(y_train, [split_index])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading model weights for Round 1...\n",
      "{\"error\":{\"code\":\"InternalError\",\"message\":\"Internal server error occurred while processing the request.\"}}\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Failed to upload model weights. Status code: 500",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mupload_model_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./workspace/sandbox_common/user\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43muser_id\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_cert.pem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                                 \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./workspace/sandbox_common/user\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43muser_id\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_privk.pem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mround_no\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_model_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[13], line 134\u001b[0m, in \u001b[0;36mupload_model_weights\u001b[0;34m(model_weights, user_cert, user_key, round_no, model_id)\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel weights uploaded successfully for Round \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mround_no\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 134\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to upload model weights. Status code: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mException\u001b[0m: Failed to upload model weights. Status code: 500"
     ]
    }
   ],
   "source": [
    "upload_model_weights(\"\", f\"./workspace/sandbox_common/user{user_id}_cert.pem\",\n",
    "                                 f\"./workspace/sandbox_common/user{user_id}_privk.pem\", round_no, model_id=initial_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing the global model...\n",
      "Training model for User 0, Round 0...\n",
      "Epoch 1/2\n",
      "938/938 [==============================] - 13s 13ms/step - loss: 0.6123 - accuracy: 0.9028 - val_loss: 0.1228 - val_accuracy: 0.9624\n",
      "Epoch 2/2\n",
      "938/938 [==============================] - 13s 13ms/step - loss: 0.1058 - accuracy: 0.9700 - val_loss: 0.0987 - val_accuracy: 0.9708\n",
      "Serializing the model...\n",
      "Uploading initial global model...\n",
      "Initial global model 'CNNModel' (ID: 5) uploaded successfully.\n",
      "Attempting to download model for User 0, Round 0, Attempt 1...\n"
     ]
    }
   ],
   "source": [
    "global_model = create_model()\n",
    "train_model(global_model, X_train_user0, y_train_user0, X_test, y_test, user_id=0, round_no=0)\n",
    "\n",
    "# Serialize and upload initial global model\n",
    "model_base64 = serialize_model(global_model)\n",
    "\n",
    "initial_model_id = upload_initial_model(model_base64, \"./workspace/sandbox_common/user0_cert.pem\",\n",
    "                                        \"./workspace/sandbox_common/user0_privk.pem\")\n",
    "\n",
    "if initial_model_id is None:\n",
    "    raise Exception(\"Failed to upload the initial global model. Stopping the process.\")\n",
    "\n",
    "# Wait for some time after initial upload\n",
    "time.sleep(1)  # Wait for 10 seconds\n",
    "\n",
    "# Federated Learning Process\n",
    "num_rounds = 4  # Number of training rounds\n",
    "user_losses = {0: [], 1: []}  # To track losses for each user\n",
    "\n",
    "# Download the latest global model once for each client\n",
    "global_model = download_model(\n",
    "    \"./workspace/sandbox_common/user0_cert.pem\",\n",
    "    \"./workspace/sandbox_common/user0_privk.pem\",\n",
    "    user_id=0, round_no=0, model_id=initial_model_id\n",
    ")\n",
    "\n",
    "# Initialize the local models for both users\n",
    "local_model_user0 = global_model\n",
    "local_model_user1 = global_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for User 0, Round 1...\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 13s 13ms/step - loss: 0.0759 - accuracy: 0.9770 - val_loss: 0.0886 - val_accuracy: 0.9756\n",
      "Epoch 2/2\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.0663 - accuracy: 0.9797 - val_loss: 0.0705 - val_accuracy: 0.9792\n",
      "model_weights [array([[[[-4.83835526e-02, -9.01561230e-02, -6.95986971e-02,\n",
      "          -1.75120607e-02, -4.39985208e-02,  1.22273611e-02,\n",
      "           6.21072575e-02, -1.08163901e-01,  5.08414395e-02,\n",
      "           6.59360439e-02,  4.02707085e-02,  7.56294467e-03,\n",
      "          -1.11561500e-01, -9.46643502e-02,  1.15830423e-02,\n",
      "          -6.74603954e-02,  4.13342826e-02, -1.25949383e-01,\n",
      "           3.69196311e-02, -7.71981925e-02, -5.78874126e-02,\n",
      "          -2.40459796e-02,  5.08746617e-02, -5.00438847e-02,\n",
      "          -3.05551440e-02,  1.90862864e-02,  1.05121685e-02,\n",
      "          -5.79367392e-02,  2.77770460e-02, -2.38991771e-02,\n",
      "           1.73046149e-03, -1.57787263e-01, -8.74455273e-02,\n",
      "          -9.88131505e-04,  2.67324839e-02,  4.90787765e-03,\n",
      "           3.84173952e-02, -3.25496718e-02, -7.91718438e-02,\n",
      "          -1.03327014e-01, -1.61193113e-03, -5.58701009e-02,\n",
      "          -9.30833891e-02,  5.80191165e-02, -3.93025763e-02,\n",
      "          -8.25387333e-03, -1.00934736e-01,  4.63357754e-03,\n",
      "          -1.15207424e-02, -7.38864690e-02,  1.08741466e-02,\n",
      "          -7.36503676e-02, -3.43449377e-02, -5.90085164e-02,\n",
      "           1.05162365e-02,  1.49515476e-02, -2.31524613e-02,\n",
      "          -8.66887569e-02, -9.09196585e-02,  4.08613682e-02,\n",
      "           1.76473707e-03, -1.69576257e-02,  4.34706248e-02,\n",
      "           8.45783502e-02]],\n",
      "\n",
      "        [[ 6.77916035e-02,  2.82826051e-02,  1.85484048e-02,\n",
      "          -4.59247790e-02, -1.76677406e-02, -3.31819020e-02,\n",
      "          -5.98811805e-02, -4.83388379e-02, -9.16296020e-02,\n",
      "          -6.72017187e-02,  4.05699946e-02,  1.22367367e-02,\n",
      "          -1.45036040e-03, -1.49248987e-02, -5.02441563e-02,\n",
      "           1.49706483e-01,  4.32628319e-02, -5.33310845e-02,\n",
      "          -5.44400625e-02, -2.18873862e-02,  3.04749925e-02,\n",
      "           6.02483563e-02, -8.46826956e-02, -1.30168172e-02,\n",
      "           1.06608637e-01, -6.13587983e-02,  2.96240370e-03,\n",
      "           2.73030903e-02,  1.17901936e-02,  3.40291858e-02,\n",
      "          -1.55993495e-02,  5.56731671e-02,  6.04064874e-02,\n",
      "          -9.38632041e-02, -4.45356779e-02, -4.25358526e-02,\n",
      "          -1.53511949e-02, -7.70850554e-02, -3.95655818e-02,\n",
      "          -2.62224786e-02,  8.78214017e-02, -2.23256014e-02,\n",
      "           6.19051792e-02, -3.14841531e-02,  3.63403298e-02,\n",
      "           3.34346178e-03,  4.36254451e-03,  3.09183970e-02,\n",
      "          -2.53075175e-02,  3.61202545e-02, -4.64127250e-02,\n",
      "           2.07390338e-02,  8.75161067e-02, -1.40432045e-01,\n",
      "          -1.92673989e-02, -3.79952937e-02,  6.77367859e-03,\n",
      "          -3.91957015e-02,  4.25338894e-02,  3.80277559e-02,\n",
      "           2.98563726e-02, -8.84282589e-02,  1.58538241e-02,\n",
      "           4.35864329e-02]],\n",
      "\n",
      "        [[ 3.04526556e-02,  5.62400520e-02,  2.91755740e-02,\n",
      "          -1.14000790e-01,  2.97960341e-02, -1.10702984e-01,\n",
      "          -5.07674515e-02, -6.50288304e-03, -4.19517010e-02,\n",
      "          -5.07099777e-02, -2.48672478e-02,  4.06599790e-02,\n",
      "          -1.17512144e-01, -6.97263777e-02, -4.98560369e-02,\n",
      "          -6.07045479e-02, -4.22857963e-02, -3.01408526e-02,\n",
      "          -8.58893245e-02, -6.11279793e-02, -1.01268880e-01,\n",
      "          -5.62133491e-02, -6.44043554e-03,  2.38927901e-02,\n",
      "          -8.98644179e-02, -2.37521306e-02,  2.39284895e-02,\n",
      "          -9.14676264e-02,  5.18172532e-02, -7.51346955e-03,\n",
      "          -2.84193326e-02, -1.53936725e-02, -1.25800550e-01,\n",
      "          -2.98164748e-02,  4.08130512e-02,  1.44389328e-02,\n",
      "          -4.36995514e-02,  4.72029224e-02, -7.28254989e-02,\n",
      "          -2.56549884e-02, -7.00751469e-02,  5.06053343e-02,\n",
      "          -4.26103845e-02, -8.87192562e-02, -4.81414720e-02,\n",
      "          -7.48597039e-03, -2.59953253e-02,  1.83802377e-02,\n",
      "           3.29069532e-02,  3.29287946e-02,  5.45720290e-03,\n",
      "          -6.50420552e-03, -1.07739337e-01,  3.79668400e-02,\n",
      "          -2.41507310e-02, -6.55634049e-03, -8.98561999e-03,\n",
      "           5.10358140e-02,  1.38068683e-02, -1.00935593e-01,\n",
      "          -4.49941829e-02,  5.83600774e-02, -8.01325515e-02,\n",
      "          -1.18045963e-01]]],\n",
      "\n",
      "\n",
      "       [[[ 4.04759916e-03,  3.51277925e-02, -3.45552750e-02,\n",
      "           5.80082312e-02,  5.83964575e-04, -1.04103945e-01,\n",
      "          -1.15717798e-01,  5.55457063e-02,  1.08375791e-02,\n",
      "          -1.11281589e-01, -5.46522662e-02,  3.77415195e-02,\n",
      "          -5.53792976e-02, -1.85067505e-02, -1.80825032e-02,\n",
      "          -7.29835406e-02,  9.44629777e-03, -3.74251753e-02,\n",
      "          -6.79339394e-02, -1.89089812e-02,  6.94230571e-02,\n",
      "           7.70768002e-02,  1.80212185e-02, -1.17992468e-01,\n",
      "          -4.33003567e-02,  6.47148490e-02,  1.94351152e-02,\n",
      "          -1.35246381e-01,  1.16219511e-03,  7.19166994e-02,\n",
      "           2.02029943e-02, -8.79143029e-02, -9.79181156e-02,\n",
      "          -5.29638939e-02, -7.07628876e-02,  5.52184433e-02,\n",
      "          -9.32702888e-03,  1.76505428e-02,  3.45796123e-02,\n",
      "          -4.69980687e-02, -1.07976057e-01, -1.19198568e-01,\n",
      "           1.84101090e-02,  6.47898316e-02, -5.60500063e-02,\n",
      "           3.74829173e-02,  2.93556638e-02,  3.44790630e-02,\n",
      "           4.75210361e-02,  1.11163072e-01,  1.31910881e-02,\n",
      "          -8.96994770e-02, -9.92678702e-02,  9.09151584e-02,\n",
      "           3.39591280e-02,  3.70803550e-02,  4.52032574e-02,\n",
      "          -3.98671329e-02,  1.20632665e-03, -6.35293424e-02,\n",
      "           5.41384853e-02, -2.90613808e-02, -2.80208942e-02,\n",
      "           3.05246357e-02]],\n",
      "\n",
      "        [[-7.15398788e-02,  8.51208437e-03,  5.65972142e-02,\n",
      "          -9.65437070e-02,  5.27285412e-02,  5.48848249e-02,\n",
      "          -1.01384364e-01,  4.36664671e-02, -5.65401204e-02,\n",
      "          -4.77485731e-02,  7.76806555e-04,  2.40510926e-02,\n",
      "          -9.67160892e-03, -2.13570893e-04,  3.68105061e-02,\n",
      "           5.90350106e-02,  3.62851453e-04,  2.97416672e-02,\n",
      "           6.19866466e-03,  1.12355873e-02,  3.72370556e-02,\n",
      "           1.56772714e-02, -5.21461107e-02, -3.83116193e-02,\n",
      "          -1.61910560e-02, -3.51892896e-02,  3.87042239e-02,\n",
      "          -7.92240500e-02,  5.45446463e-02,  4.12417538e-02,\n",
      "           3.46595906e-02, -1.11512713e-01, -1.18333586e-01,\n",
      "          -7.17474073e-02,  4.00086753e-02, -1.29910195e-02,\n",
      "           5.02922051e-02, -2.47505866e-02,  2.31105136e-03,\n",
      "          -4.64703739e-02, -1.02494664e-01,  3.97133455e-02,\n",
      "          -1.60048082e-02,  5.85703040e-03, -2.41512302e-02,\n",
      "           5.83554655e-02, -2.70697102e-03,  6.36862069e-02,\n",
      "           5.49907126e-02, -2.14780215e-02, -7.61634186e-02,\n",
      "          -1.09867886e-01, -1.04561038e-01, -5.29249646e-02,\n",
      "          -1.28519777e-02, -2.06835754e-02,  6.48037046e-02,\n",
      "           4.22874466e-04,  3.62132490e-02, -2.15560198e-02,\n",
      "          -3.91495749e-02,  2.71516945e-02,  7.48821795e-02,\n",
      "          -5.23642413e-02]],\n",
      "\n",
      "        [[-8.90173092e-02, -9.98209193e-02,  1.38404751e-02,\n",
      "          -1.25791639e-01, -2.59199757e-02, -3.04700956e-02,\n",
      "          -8.23910013e-02, -2.38972213e-02, -2.90934276e-02,\n",
      "           3.29359435e-02, -9.35541689e-02, -3.77340168e-02,\n",
      "          -1.07039884e-01, -3.88062596e-02, -1.00422986e-01,\n",
      "          -2.02062771e-01,  4.34134603e-02, -8.93568471e-02,\n",
      "          -1.59356538e-02, -5.04779071e-02, -3.58048826e-02,\n",
      "          -7.55377859e-02,  6.01488771e-03,  6.57310486e-02,\n",
      "          -1.02590978e-01, -2.58180518e-02,  9.56361648e-03,\n",
      "           6.80240244e-03,  4.33831550e-02,  3.02422093e-03,\n",
      "           4.60343286e-02, -6.65351078e-02,  6.03474006e-02,\n",
      "          -2.25979537e-02,  3.00210603e-02,  3.65278535e-02,\n",
      "          -7.06023537e-03, -4.57992554e-02,  7.94058144e-02,\n",
      "           7.73299113e-02, -1.37359619e-01, -9.47366580e-02,\n",
      "           4.79942560e-02, -2.89850384e-02,  6.59876466e-02,\n",
      "          -3.02965026e-02,  3.96136045e-02, -5.78493662e-02,\n",
      "          -4.89055738e-02,  5.33610955e-03, -6.84078485e-02,\n",
      "          -8.49469602e-02, -1.04262322e-01, -9.78049263e-03,\n",
      "          -3.24345715e-02,  7.03385426e-03, -9.64309946e-02,\n",
      "          -2.50590127e-02, -1.20023012e-01, -8.62579718e-02,\n",
      "          -3.39771109e-03, -4.19608280e-02, -5.89922741e-02,\n",
      "          -4.25509624e-02]]],\n",
      "\n",
      "\n",
      "       [[[ 4.27769870e-02,  2.37407144e-02, -1.13606043e-01,\n",
      "           5.08229360e-02, -4.88293581e-02,  3.49887796e-02,\n",
      "           1.57356802e-02, -9.40201581e-02, -6.20807447e-02,\n",
      "           4.44848351e-02,  5.15680574e-02, -5.56309223e-02,\n",
      "          -5.02946153e-02, -8.93092155e-03,  5.44688664e-02,\n",
      "          -1.70430467e-01,  2.70091593e-02,  1.15841394e-02,\n",
      "           3.42348069e-02,  7.06708580e-02, -4.33596149e-02,\n",
      "          -7.88480863e-02, -8.41211602e-02,  2.70840172e-02,\n",
      "          -1.38040883e-02, -6.67498484e-02, -3.48015688e-02,\n",
      "           5.35873696e-02, -1.33403927e-01, -9.92759466e-02,\n",
      "          -8.12223554e-03, -7.62450173e-02, -7.53847286e-02,\n",
      "          -2.07159389e-02,  3.50215547e-02,  4.10715118e-02,\n",
      "           6.90794140e-02, -4.51203212e-02, -3.85766141e-02,\n",
      "          -4.17198837e-02,  2.48878505e-02,  4.40081395e-02,\n",
      "           8.74287728e-03, -6.85300305e-02, -1.27809212e-01,\n",
      "          -1.34887069e-01,  8.87926146e-02, -4.02583703e-02,\n",
      "          -4.81270440e-02, -3.66766192e-03,  4.29803394e-02,\n",
      "          -1.43828113e-02, -2.53913440e-02, -1.54143004e-02,\n",
      "           3.76795442e-03, -2.16109511e-02, -5.16418628e-02,\n",
      "          -3.46135832e-02,  6.42913952e-03,  5.47428615e-03,\n",
      "           2.28634733e-03, -1.57826580e-02,  6.54346719e-02,\n",
      "          -1.27963081e-01]],\n",
      "\n",
      "        [[-1.66012272e-02, -6.32662848e-02, -7.26041943e-02,\n",
      "          -9.34426710e-02,  5.00820428e-02,  4.07249853e-02,\n",
      "           1.40551301e-02, -5.92954271e-02, -1.61312610e-01,\n",
      "          -4.61626127e-02, -4.94829193e-02, -7.94632509e-02,\n",
      "           5.06334491e-02, -5.41872904e-02,  5.95624745e-02,\n",
      "          -1.80404082e-01, -2.96877772e-02,  6.64400011e-02,\n",
      "           6.75965920e-02, -1.18528893e-02,  3.91159113e-03,\n",
      "           3.00792847e-02, -4.92671058e-02, -1.11702234e-01,\n",
      "           5.74051850e-02,  8.14395472e-02, -1.77200157e-02,\n",
      "           2.10055020e-02, -8.98671895e-02,  9.41527728e-03,\n",
      "           2.81255692e-02,  2.17756666e-02,  5.22858463e-02,\n",
      "          -5.99913532e-03,  4.61372212e-02,  2.38062423e-02,\n",
      "          -3.88299711e-02,  6.96498319e-04, -1.04457781e-01,\n",
      "          -1.15785614e-01, -6.69917390e-02, -8.43909681e-02,\n",
      "           4.04745266e-02,  4.56253588e-02,  3.77020761e-02,\n",
      "          -5.08454628e-02, -9.84075591e-02, -5.63285574e-02,\n",
      "          -1.04562305e-02, -2.58527640e-02, -1.02019303e-01,\n",
      "           3.71510349e-02,  1.01197977e-02, -1.28086746e-01,\n",
      "          -1.18584342e-01, -9.71638262e-02, -4.32474948e-02,\n",
      "           4.49242443e-02, -3.50386091e-02, -5.84648140e-02,\n",
      "          -7.70774786e-04, -1.42431650e-02, -6.10787906e-02,\n",
      "          -7.68689960e-02]],\n",
      "\n",
      "        [[ 3.99682634e-02, -1.11755252e-01, -5.29662222e-02,\n",
      "          -9.26333442e-02, -7.06929117e-02, -1.40906556e-03,\n",
      "          -7.14670494e-02, -4.55143414e-02,  4.00900468e-02,\n",
      "           5.14565855e-02,  9.11390223e-03,  3.50761190e-02,\n",
      "          -2.82099843e-02, -7.50422478e-05, -4.12999885e-03,\n",
      "           3.46011706e-02, -1.03819422e-01, -5.27528375e-02,\n",
      "          -1.22366972e-01, -4.83757071e-02, -1.17878646e-01,\n",
      "           3.12264636e-02,  6.07016981e-02, -1.16368100e-01,\n",
      "           3.63452137e-02,  3.22997868e-02, -7.45555758e-02,\n",
      "          -9.44912732e-02, -9.15323570e-02,  8.39913543e-03,\n",
      "           7.59893155e-04, -2.68286257e-03,  5.92238316e-03,\n",
      "          -8.32928568e-02, -3.93059291e-02, -4.02232213e-03,\n",
      "           2.03224309e-02,  3.88552658e-02, -6.44994900e-02,\n",
      "           3.32608633e-02,  4.16520163e-02,  2.57105418e-02,\n",
      "          -4.76173544e-03, -4.27627601e-02,  2.75493767e-02,\n",
      "          -8.84610265e-02, -9.99641567e-02,  5.64003624e-02,\n",
      "          -4.13338579e-02, -3.80722666e-03,  2.06763539e-02,\n",
      "           6.32100850e-02,  4.92705107e-02, -5.30140363e-02,\n",
      "          -5.19804610e-03, -3.34501266e-02,  3.72209027e-02,\n",
      "           1.11557106e-02, -4.34306450e-03,  1.92143582e-02,\n",
      "          -1.35557368e-01,  1.70006033e-03, -5.35071306e-02,\n",
      "          -7.39520928e-03]]]], dtype=float32), array([-0.09402043, -0.07234674, -0.01807323, -0.01671551, -0.03818161,\n",
      "       -0.05200814, -0.01303178, -0.0123994 ,  0.0590037 , -0.05377447,\n",
      "       -0.01134774, -0.04739753, -0.00902636,  0.        , -0.02338243,\n",
      "       -0.01650157, -0.07910175,  0.01549411, -0.05248111, -0.01049479,\n",
      "       -0.00404517, -0.03559754, -0.05777496, -0.00736125, -0.05188006,\n",
      "       -0.01911377, -0.02200143, -0.01262807, -0.00492901, -0.0391906 ,\n",
      "       -0.02410201, -0.0174789 , -0.0062635 , -0.00475523, -0.04812786,\n",
      "       -0.04399057, -0.04545007, -0.03714221, -0.01141033, -0.03445803,\n",
      "       -0.01642949, -0.01444673,  0.0677915 , -0.04363808,  0.10151022,\n",
      "       -0.01613889,  0.03371274, -0.08533884, -0.03404162, -0.03796171,\n",
      "       -0.03283552, -0.01074671,  0.03283399, -0.0025368 , -0.08785401,\n",
      "       -0.08519771, -0.03447754, -0.03578745, -0.07391357, -0.01822937,\n",
      "       -0.041181  , -0.06419887,  0.09298036, -0.0121284 ], dtype=float32), array([[[[ 2.57072281e-02, -9.13639441e-02,  6.31837249e-02, ...,\n",
      "           7.81081710e-03, -2.02657096e-02, -6.97709024e-02],\n",
      "         [-8.24030954e-03,  1.50300916e-02, -8.40174705e-02, ...,\n",
      "           5.60085103e-02,  2.81951409e-02,  5.49279265e-02],\n",
      "         [ 2.84923967e-02, -1.43598495e-02,  7.99699104e-04, ...,\n",
      "           9.10177231e-02, -5.63084669e-02,  5.16971666e-03],\n",
      "         ...,\n",
      "         [ 2.71709748e-02, -7.68564641e-02, -9.58291292e-02, ...,\n",
      "          -5.75068071e-02, -1.33003965e-02, -3.85907218e-02],\n",
      "         [ 6.99192379e-03,  4.28770036e-02, -3.72648686e-02, ...,\n",
      "           2.93141580e-03, -9.84545797e-03, -4.54583904e-03],\n",
      "         [-3.13733742e-02,  3.42221633e-02,  1.69259794e-02, ...,\n",
      "           1.28456522e-02, -2.65086088e-02, -3.38344388e-02]],\n",
      "\n",
      "        [[-2.61187740e-02, -7.59922564e-02, -4.29675318e-02, ...,\n",
      "           2.85301451e-02, -1.52918231e-02, -5.85451461e-02],\n",
      "         [ 5.37660299e-03, -5.55516258e-02,  1.96197908e-02, ...,\n",
      "          -1.53512526e-02, -1.99597999e-02, -5.27001806e-02],\n",
      "         [-2.14603096e-02, -1.71730835e-02, -7.17576295e-02, ...,\n",
      "           5.26188836e-02,  8.37884471e-02, -1.91646963e-02],\n",
      "         ...,\n",
      "         [-6.06293529e-02, -1.30255193e-01, -8.57028216e-02, ...,\n",
      "           6.86935782e-02, -1.81043409e-02,  4.30175141e-02],\n",
      "         [ 1.78754516e-02,  4.16210815e-02, -4.47062813e-02, ...,\n",
      "           2.42932998e-02,  2.65345592e-02, -6.00004531e-02],\n",
      "         [-2.92056538e-02,  5.47395088e-02,  9.50742662e-02, ...,\n",
      "          -3.32006812e-02, -1.07923999e-01,  2.76218392e-02]],\n",
      "\n",
      "        [[ 6.10512346e-02,  7.74568990e-02,  4.78661694e-02, ...,\n",
      "           1.08491965e-02,  3.34103568e-03, -1.76812243e-02],\n",
      "         [-1.11533433e-01, -8.45044032e-02,  3.16623226e-02, ...,\n",
      "          -5.42265587e-02, -4.10179272e-02, -5.60378470e-02],\n",
      "         [ 7.22712139e-04, -2.27167998e-02, -2.81078313e-02, ...,\n",
      "           9.79219377e-03, -2.26444174e-02, -9.55768749e-02],\n",
      "         ...,\n",
      "         [-7.66611025e-02, -6.19805343e-02, -9.81100798e-02, ...,\n",
      "          -5.31517789e-02,  9.73365530e-02, -1.02094948e-01],\n",
      "         [-1.08343773e-01,  2.81102005e-02,  1.94634832e-02, ...,\n",
      "           6.94955438e-02,  6.55464754e-02,  8.02096203e-02],\n",
      "         [ 4.10379097e-02, -3.18790153e-02,  1.89676508e-01, ...,\n",
      "           5.18341698e-02,  6.11863099e-02,  1.59161463e-02]]],\n",
      "\n",
      "\n",
      "       [[[-3.86407860e-02, -3.25469784e-02,  1.13279819e-01, ...,\n",
      "           3.19839641e-02,  7.22832233e-02, -7.84445181e-02],\n",
      "         [-1.71737317e-02, -6.94880337e-02,  3.88580449e-02, ...,\n",
      "          -1.99356303e-02, -5.34542874e-02,  8.49877670e-03],\n",
      "         [ 4.48219068e-02,  9.89721119e-02,  6.21509142e-02, ...,\n",
      "          -4.22302336e-02,  3.04147284e-02,  1.24056749e-01],\n",
      "         ...,\n",
      "         [-5.07841483e-02, -4.87369038e-02, -3.56080942e-02, ...,\n",
      "           6.29279716e-03, -7.18559176e-02,  9.13355127e-02],\n",
      "         [ 4.11872603e-02,  2.99052484e-02, -6.10194281e-02, ...,\n",
      "          -4.31219786e-02, -1.04295895e-01, -7.14024827e-02],\n",
      "         [-3.11733503e-02,  3.12948786e-03, -4.93916348e-02, ...,\n",
      "          -6.51595294e-02,  4.52391356e-02, -9.00829732e-02]],\n",
      "\n",
      "        [[-1.14104869e-02, -1.48023833e-02, -3.30487117e-02, ...,\n",
      "          -8.01580176e-02, -8.90880898e-02,  2.11359039e-02],\n",
      "         [-1.74393095e-02, -1.54529670e-02, -2.24088151e-02, ...,\n",
      "          -1.08056748e-02,  4.04551253e-02, -5.91021143e-02],\n",
      "         [ 5.33802211e-02, -3.66801657e-02, -1.44626910e-03, ...,\n",
      "           6.69555664e-02, -4.24589850e-02,  6.29640967e-02],\n",
      "         ...,\n",
      "         [ 9.31105204e-03,  6.80771172e-02, -1.74372159e-02, ...,\n",
      "           3.99897285e-02,  7.61942491e-02, -8.39174762e-02],\n",
      "         [ 1.42867351e-02,  5.41721955e-02,  1.01408903e-02, ...,\n",
      "          -4.06844728e-02, -2.59578470e-02,  6.95314556e-02],\n",
      "         [-3.84555645e-02,  7.32781962e-02,  4.12197113e-02, ...,\n",
      "          -6.79334849e-02,  7.13687837e-02,  1.05344035e-01]],\n",
      "\n",
      "        [[-4.59850356e-02, -1.01791583e-01,  2.62628961e-02, ...,\n",
      "           2.88985819e-02, -5.48631214e-02,  6.91271201e-02],\n",
      "         [ 7.51319900e-02, -3.18533182e-03, -4.13450524e-02, ...,\n",
      "          -6.87497621e-03,  2.77381833e-03, -1.60838738e-02],\n",
      "         [-4.97058667e-02,  5.44092916e-02, -1.03198104e-01, ...,\n",
      "           5.87311424e-02, -7.54581690e-02, -5.40731587e-02],\n",
      "         ...,\n",
      "         [ 4.94351909e-02,  4.69682328e-02, -8.43702108e-02, ...,\n",
      "          -1.35142412e-02,  5.01449965e-02, -4.36306074e-02],\n",
      "         [-6.90708831e-02, -1.46584855e-02, -4.73460630e-02, ...,\n",
      "          -8.96229744e-02, -1.00715803e-02, -2.16251090e-02],\n",
      "         [-8.01212341e-02,  3.34364027e-02,  4.48786467e-02, ...,\n",
      "           3.02424636e-02,  4.71001072e-03,  9.18752328e-02]]],\n",
      "\n",
      "\n",
      "       [[[-4.17013355e-02, -1.14437155e-01, -1.99696030e-02, ...,\n",
      "           1.78392902e-02, -3.99131626e-02, -2.36090720e-02],\n",
      "         [-7.95854852e-02,  6.36740699e-02,  9.46152839e-04, ...,\n",
      "          -1.99845415e-02, -2.54416876e-02,  4.25394028e-02],\n",
      "         [-2.40133721e-02,  1.29849464e-03,  1.25712017e-04, ...,\n",
      "          -6.38698488e-02, -5.11667691e-02,  3.40234041e-02],\n",
      "         ...,\n",
      "         [ 4.85444814e-03,  5.27127981e-02, -1.46525502e-02, ...,\n",
      "           6.65805349e-03,  5.04625142e-02,  2.37976629e-02],\n",
      "         [-5.98812988e-03,  5.85333966e-02, -6.07038997e-02, ...,\n",
      "          -3.18922922e-02, -1.19384915e-01, -6.39991164e-02],\n",
      "         [-1.92368459e-02,  1.42463624e-01, -9.92475525e-02, ...,\n",
      "          -5.43402657e-02, -7.34891882e-03, -1.10267296e-01]],\n",
      "\n",
      "        [[ 5.99801317e-02, -1.80954989e-02,  4.37262915e-02, ...,\n",
      "          -4.92473654e-02, -7.40420595e-02, -4.92135808e-02],\n",
      "         [-8.79953951e-02,  1.27895754e-02, -1.96330436e-02, ...,\n",
      "          -2.84343455e-02, -9.24799964e-02,  9.63807106e-03],\n",
      "         [-2.11792975e-03, -1.50066214e-02,  2.13886090e-02, ...,\n",
      "           5.58846295e-02, -2.93535702e-02, -8.78700167e-02],\n",
      "         ...,\n",
      "         [ 7.55048217e-03,  3.07721198e-02, -7.42081776e-02, ...,\n",
      "           5.17051555e-02,  1.68390386e-02, -3.08858566e-02],\n",
      "         [ 5.00428490e-03,  5.28680794e-02,  5.89202084e-02, ...,\n",
      "          -7.56158531e-02, -8.26069415e-02, -2.53505334e-02],\n",
      "         [ 4.61659990e-02,  1.57938264e-02,  3.61997224e-02, ...,\n",
      "           6.16634712e-02, -6.60050586e-02, -8.16534236e-02]],\n",
      "\n",
      "        [[-3.72403674e-02, -5.02441786e-02, -6.94241375e-02, ...,\n",
      "          -4.34882157e-02, -2.16709450e-03,  2.43304614e-02],\n",
      "         [ 6.86769336e-02,  3.83763611e-02, -9.02283639e-02, ...,\n",
      "           2.95533910e-02, -1.08701706e-01, -6.49077967e-02],\n",
      "         [-1.04166577e-02, -1.22709304e-01, -6.68585971e-02, ...,\n",
      "          -2.84790639e-02,  1.25241037e-02, -9.12486687e-02],\n",
      "         ...,\n",
      "         [-1.94029752e-02,  4.86106016e-02, -6.63820431e-02, ...,\n",
      "          -6.41548336e-02,  7.75411427e-02,  5.96055128e-02],\n",
      "         [-7.07640946e-02,  4.67629870e-04,  1.03405472e-02, ...,\n",
      "          -9.07283798e-02, -7.10938200e-02, -6.35250732e-02],\n",
      "         [ 6.29173666e-02,  8.17954466e-02, -3.98597354e-03, ...,\n",
      "           3.69555615e-02,  9.72037669e-03, -1.30445678e-02]]]],\n",
      "      dtype=float32), array([-0.07881677, -0.01956431, -0.00128303, -0.02827159, -0.04746072,\n",
      "       -0.02277753, -0.04056416, -0.01700765, -0.01981985, -0.04796317,\n",
      "       -0.07480362, -0.04116509, -0.01236682,  0.01469969, -0.0044292 ,\n",
      "       -0.03791605, -0.04113807, -0.03444358, -0.01135563, -0.0290559 ,\n",
      "       -0.05886799, -0.01597181, -0.05067625, -0.00568302, -0.02282386,\n",
      "       -0.05033022, -0.01242602,  0.03953573, -0.01003059, -0.05421593,\n",
      "       -0.04064359, -0.05900451], dtype=float32), array([[-0.00892372, -0.06416239,  0.10718682, ..., -0.03602963,\n",
      "         0.02743878, -0.04318496],\n",
      "       [ 0.02599007, -0.05142215, -0.04316425, ..., -0.01599547,\n",
      "         0.0292622 ,  0.01684585],\n",
      "       [ 0.01854344, -0.04648869, -0.01583146, ..., -0.04344691,\n",
      "         0.07084011,  0.08379469],\n",
      "       ...,\n",
      "       [ 0.01451358, -0.01292017,  0.04533967, ..., -0.02211   ,\n",
      "         0.02916146, -0.0630767 ],\n",
      "       [ 0.00311886, -0.05093642,  0.05533024, ..., -0.08537055,\n",
      "         0.05848798, -0.00695628],\n",
      "       [-0.05610268,  0.13113488,  0.05820251, ...,  0.06050671,\n",
      "        -0.06775079, -0.03648198]], dtype=float32), array([ 0.01276363,  0.03488181,  0.01572092, -0.01380633, -0.01800026,\n",
      "       -0.01087282, -0.00833367, -0.02008109,  0.04501621, -0.02223083],\n",
      "      dtype=float32)]\n",
      "Uploading model weights for Round 1...\n",
      "{\"error\":{\"code\":\"InternalError\",\"message\":\"Internal server error occurred while processing the request.\"}}\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Failed to upload model weights. Status code: 500",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Upload model weights only if they are not empty\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_weights:\n\u001b[0;32m---> 17\u001b[0m     \u001b[43mupload_model_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./workspace/sandbox_common/user\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43muser_id\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_cert.pem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m                         \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./workspace/sandbox_common/user\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43muser_id\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_privk.pem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mround_no\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_model_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel weights are empty, skipping upload...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[13], line 134\u001b[0m, in \u001b[0;36mupload_model_weights\u001b[0;34m(model_weights, user_cert, user_key, round_no, model_id)\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel weights uploaded successfully for Round \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mround_no\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 134\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to upload model weights. Status code: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mException\u001b[0m: Failed to upload model weights. Status code: 500"
     ]
    }
   ],
   "source": [
    "# Initialize and train the global model (User 0)\n",
    "\n",
    "for round_no in range(1, num_rounds + 1):\n",
    "    for user_id in range(2):  # Two users: 0 and 1\n",
    "        # Train the local model on the user's data\n",
    "        X_train_user = X_train_user0 if user_id == 0 else X_train_user1\n",
    "        y_train_user = y_train_user0 if user_id == 0 else y_train_user1\n",
    "        loss = train_model(local_model_user0 if user_id == 0 else local_model_user1,\n",
    "                           X_train_user, y_train_user, X_test, y_test, user_id, round_no)\n",
    "        user_losses[user_id].extend(loss)\n",
    "\n",
    "        # Serialize and upload the updated model weights for the current round\n",
    "        model_weights = local_model_user0.get_weights() if user_id == 0 else local_model_user1.get_weights()\n",
    "        print(\"model_weights\",model_weights)\n",
    "        # Upload model weights only if they are not empty\n",
    "        if model_weights:\n",
    "            upload_model_weights(model_weights, f\"./workspace/sandbox_common/user{user_id}_cert.pem\",\n",
    "                                 f\"./workspace/sandbox_common/user{user_id}_privk.pem\", round_no, model_id=initial_model_id)\n",
    "        else:\n",
    "            print(\"Model weights are empty, skipping upload...\")\n",
    "\n",
    "    # Aggregate weights after each user's training round\n",
    "    aggregate_weights(initial_model_id, \"./workspace/sandbox_common/member0_cert.pem\",\n",
    "                      \"./workspace/sandbox_common/member0_privk.pem\")\n",
    "\n",
    "    # Download global model weights after aggregation and update local models\n",
    "    global_model_weights = download_global_model_weights(\n",
    "        \"./workspace/sandbox_common/user0_cert.pem\", \"./workspace/sandbox_common/user0_privk.pem\",\n",
    "        model_id=initial_model_id\n",
    "    )\n",
    "\n",
    "    if global_model_weights:\n",
    "        # Update local models with global weights\n",
    "        local_model_user0.set_weights([np.array(w) for w in global_model_weights])\n",
    "        local_model_user1.set_weights([np.array(w) for w in global_model_weights])\n",
    "        print(\"Global model weights updated for both clients.\")\n",
    "\n",
    "print(\"Federated Learning Process Completed.\")\n",
    "\n",
    "# Plot loss graphs for each user\n",
    "plot_loss(user_losses)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
